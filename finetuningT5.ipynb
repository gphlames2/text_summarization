{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\braim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (C:/Users/braim/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
      "Found cached dataset cnn_dailymail (C:/Users/braim/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
      "Found cached dataset cnn_dailymail (C:/Users/braim/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "val_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")\n",
    "test_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "train_data = pd.DataFrame(train_data)\n",
    "val_data = pd.DataFrame(val_data)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "for index, text in enumerate(train_data['article']):\n",
    "    if len(text) % 512 > 1.5:\n",
    "        train_data.loc[index,'article'] = ''.join(list(text)[256:]) + ''.join(list(text)[-256:])\n",
    "    elif len(text) > 512:\n",
    "         train_data.loc[index,'article'] = ''.join(list(text)[-512:])\n",
    "    else:\n",
    "        continue\n",
    "for index, text in enumerate(val_data['article']):\n",
    "    if len(text) % 512 > 1.5:\n",
    "        val_data.loc[index,'article'] = ''.join(list(text)[256:]) + ''.join(list(text)[-256:])\n",
    "    elif len(text) > 512:\n",
    "         val_data.loc[index,'article'] = ''.join(list(text)[-512:])\n",
    "    else:\n",
    "        continue\n",
    "for index, text in enumerate(test_data['article']):\n",
    "    if len(text) % 512 > 1.5:\n",
    "        test_data.loc[index,'article'] = ''.join(list(text)[256:]) + ''.join(list(text)[-256:])\n",
    "    elif len(text) > 512:\n",
    "         test_data.loc[index,'article'] = ''.join(list(text)[-512:])\n",
    "    else:\n",
    "        continue\n",
    "train_data = datasets.Dataset(pa.Table.from_pandas(train_data))\n",
    "val_data = datasets.Dataset(pa.Table.from_pandas(val_data))\n",
    "test_data = datasets.Dataset(pa.Table.from_pandas(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braim\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "prefix = 'summarize:'\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    labels = tokenizer(text_target=examples[\"highlights\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/288 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc62c00618d544ba91329c19fac44a04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/14 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2d92f2945e44fcfad9caaca0e0b7138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(preprocess_function, batched=True)\n",
    "val_data = val_data.map(preprocess_function,batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./T5base/t5-base/256_tokens\").to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=20,\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\braim\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 287113\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 3\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 60\n",
      "  Gradient Accumulation steps = 20\n",
      "  Total optimization steps = 9570\n",
      "  Number of trainable parameters = 60506624\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='9570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/9570 : < :, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-1000\n",
      "Configuration saved in ./t5results\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-1000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-1000\\spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-2000\n",
      "Configuration saved in ./t5results\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-2000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-2000\\spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-3000\n",
      "Configuration saved in ./t5results\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-3000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-3000\\spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-4000\n",
      "Configuration saved in ./t5results\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-4000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-4000\\spiece.model\n",
      "Deleting older checkpoint [t5results\\checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-5000\n",
      "Configuration saved in ./t5results\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-5000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-5000\\spiece.model\n",
      "Deleting older checkpoint [t5results\\checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-6000\n",
      "Configuration saved in ./t5results\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-6000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-6000\\spiece.model\n",
      "Deleting older checkpoint [t5results\\checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-7000\n",
      "Configuration saved in ./t5results\\checkpoint-7000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-7000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-7000\\spiece.model\n",
      "Deleting older checkpoint [t5results\\checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-8000\n",
      "Configuration saved in ./t5results\\checkpoint-8000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-8000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-8000\\spiece.model\n",
      "Deleting older checkpoint [t5results\\checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "Saving model checkpoint to ./t5results\\checkpoint-9000\n",
      "Configuration saved in ./t5results\\checkpoint-9000\\config.json\n",
      "Model weights saved in ./t5results\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./t5results\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in ./t5results\\checkpoint-9000\\special_tokens_map.json\n",
      "Copy vocab file to ./t5results\\checkpoint-9000\\spiece.model\n",
      "Deleting older checkpoint [t5results\\checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13368\n",
      "  Batch size = 3\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=9570, training_loss=2.2067637715593773, metrics={'train_runtime': 16424.6028, 'train_samples_per_second': 34.961, 'train_steps_per_second': 0.583, 'total_flos': 7.76878419370967e+16, 'train_loss': 2.2067637715593773, 'epoch': 2.0})"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('./T5base/t5-base/256_tokens').to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "text_generator = pipeline(\n",
    "    \"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    max_length=50,\n",
    "    device=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model.save_pretrained('./T5base/t5-base/256_tokens')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def calculate_metric_on_test_ds(metric):\n",
    "    article_batches = list(generate_batch_sized_chunks(test_data['article'],1))\n",
    "    target_batches = list(generate_batch_sized_chunks(test_data['highlights'],1))\n",
    "    for article, target in tqdm(zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        generated_summary = text_generator(article)\n",
    "        metric.add_batch(predictions=generated_summary, references=target)\n",
    "    #  Finally compute and return the ROUGE scores.\n",
    "    score = metric.compute()\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 9.12\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(f\"Perplexity: {math.exp(2.21):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/11490 [00:05<1:33:58,  2.04it/s]C:\\Users\\braim\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 11490/11490 [1:35:45<00:00,  2.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       rouge1    rouge2   rougeL  rougeLsum\nfine_tuned T5-small  0.339112  0.149151  0.24515   0.296455",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fine_tuned T5-small</th>\n      <td>0.339112</td>\n      <td>0.149151</td>\n      <td>0.24515</td>\n      <td>0.296455</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_metric = load_metric('rouge')\n",
    "score = calculate_metric_on_test_ds(rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "pd.DataFrame(rouge_dict, index = ['fine_tuned T5-small'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}